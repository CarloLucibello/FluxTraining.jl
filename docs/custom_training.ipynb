{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we compose changes to the training loop together?\n",
    "\n",
    "As an example, we want to be able to do data-parallel training or GAN training, but also data-parallel GAN training.\n",
    "\n",
    "I want to give some thoughts on this and propose possible solutions to make this possible in *FastAI.jl*. \n",
    "\n",
    "Currently, implementing custom training behavior is possible by subtyping `FitPhase` and implementing `fitbatchphase!(learner, phase::MyPhase)`. However, this is not composable, i.e. it doesn't allow you to combine a `DataParallelTrainingPhase` and `GANTrainingPhase`.\n",
    "\n",
    "\n",
    "\n",
    "Below are some examples that show how the contents of `fitbatchphase!` can be changed to illustrate this. For simplicity, they don't include callbacks and state handling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular training (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: gradient not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: gradient not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[8]:2",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "# inputs: model, xs, ys, lossfn, optim, params\n",
    "grads = gradient(params) do\n",
    "    return lossfn(model(xs), ys)\n",
    "end\n",
    "update!(optim, params, sum(grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data-parallel training on CPU (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs: model, xs, ys, lossfn, optim, params\n",
    "\n",
    "grads = Array{Grads}(undef, Threads.nthreads())\n",
    "\n",
    "# run equally-sized slices of the batch in parallel (naive pseudocode)\n",
    "Threads.@threads for (i, (xs_, ys_)) in enumerate(scatter((xs, ys), Threads.nthreads()))\n",
    "    grads[i] = gradient(params) do\n",
    "        return lossfn(model(xs_), ys_)\n",
    "    end\n",
    "end\n",
    "gs = sum(grads)\n",
    "\n",
    "# do parameter update with summed gradients\n",
    "update!(optim, params, gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN training (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs: mgen, mcrit, paramsgen, paramscrit, xs_true, lossfngen, lossfncrit, optim, batchsize\n",
    "\n",
    "# critic step\n",
    "xs_fake = mgen(batchsize)\n",
    "xs = cat(xs_true, xs_fake)\n",
    "ys = onehot.(vcat(trues(batchsize), falses(batchsize)))\n",
    "\n",
    "grads = gradient(paramscrit) do\n",
    "    return lossfncrit(mcrit(xs), ys)\n",
    "end\n",
    "update!(optim, paramscrit, grads)\n",
    "\n",
    "# generator step\n",
    "grads = gradient(paramsgen) do\n",
    "    xs_fake = mgen(batchsize)\n",
    "    ys_fake = onehot.(falses(batchsize))\n",
    "    return -lossfncrit(crit(xs_fake), ys_fake)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions\n",
    "\n",
    "I have found two approaches to deal with this. **Both focus on removing execution logic from `fitbatchphase!`, making them composable with custom `Phase`s** like `GANTrainingPhase` that change\n",
    "the *semantics* of the training loop.\n",
    "\n",
    "On one hand, there are extensions to the training loop that change the *execution* (e.g. parallel and distributed CPU and GPU training), on the other hand you have those that change the *semantics* (e.g. GAN training).\n",
    "\n",
    "The proposed solutions make the assumption that different *semantics* don't need to be composed, but should be composable with different execution contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (S1) Abstract gradient step (and possibly others) out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifications to the execution of the training loop could be implemented by wrapping in an execution context.\n",
    "\n",
    "In the below example `gradientphase` could dispatch to the regular gradient calculation in (1) or the data-parallel approach (2) depending on `executionctx`.\n",
    "\n",
    "This would mean that only *semantic* changes to the training loop would use overloading of `fitbatchphase!` with a custom `FitPhase`. Changes to the *execution* work by dispatching on execution contexts, e.g. `gradientphase(::Linear, ...)` or `gradientphase(::DataParallel, ...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradientphase passes (possibly modified) state to a closure\n",
    "# in the case executionctx::DataParallel, xs_, ys_ will be slices\n",
    "# of the batch.\n",
    "grads = gradient(executionctx, params) do model_, params_, xs_, ys_, \n",
    "    return lossfn(model(xs_), ys_)\n",
    "end\n",
    "update!(optim, params, grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages**\n",
    "\n",
    "- implementation definitely doable\n",
    "\n",
    "**Disadvantages**\n",
    "\n",
    "- implementation dependent on requirements, i.e. unsure which pieces of the training step need to be overloadable and which state needs to be passed to closures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (S2) Wrapper for `model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to wrap the `model` in an execution context, e.g. `DataParallel(model)`. The wrapper is then responsible for exhibiting the correct behavior on the forward and backward pass. This is [what PyTorch does](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html?highlight=parallel#torch.nn.DataParallel).\n",
    "\n",
    "No changes to the training loop would need to be made. The implementation for the forward pass should be straightforward and similar to the above sketch (2), however I'm not sure how to make sure that the backward pass is also computed in parallel (can custom gradient definitions include multi-threading code?, what about the loss function that is not wrapped?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before training\n",
    "model = DataParallel(model)\n",
    "\n",
    "# training step doesn't change at all\n",
    "grads = gradient(params) do\n",
    "    return lossfn(model(xs), ys)\n",
    "end\n",
    "update!(optim, params, sum(grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages**\n",
    "\n",
    "- no changes needed to state and event handling\n",
    "\n",
    "**Disadvantages**\n",
    "\n",
    "- not sure if such a simple API is possible to implement for all scenarios\n",
    "- bit unelegant; model is not a pure function anymore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (12 threads) 1.5.0",
   "language": "julia",
   "name": "julia-(12-threads)-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
