{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/.julia/dev/FluxTraining/docs/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg  # src\n",
    "Pkg.activate(\"../FluxTraining/docs\")  # src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put *FluxTraining.jl* to train a model on the MNIST dataset.\n",
    "\n",
    "MNIST is simple enough that we can focus on the part where *FluxTraining.jl* comes in, the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*if you want to run this tutorial yourself, you can find the notebook file [here](https://github.com/lorenzoh/FluxTraining.jl/blob/master/docs/tutorials/mnist.ipynb)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make data loading and batching a bit easier, we'll install some additional dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[2K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/lorenzoh/DataLoaders.jl`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/dev/FluxTraining/docs/Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/dev/FluxTraining/docs/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/dev/FluxTraining/docs/Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/dev/FluxTraining/docs/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(url=\"https://github.com/lorenzoh/DataLoaders.jl\")\n",
    "Pkg.add(\"MLDataPattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import everything we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataLoaders: DataLoader\n",
    "using MLDataPattern: splitobs\n",
    "using Flux\n",
    "using FluxTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 pieces that you always need to construct and train a [`Learner`](#):\n",
    "\n",
    "- a model\n",
    "- data\n",
    "- an optimizer; and\n",
    "- a loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a `Learner`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the **data** first.\n",
    "\n",
    "*FluxTraining.jl* is agnostic of the data source. The only requirements are:\n",
    "\n",
    "- it is iterable and each iteration returns a tuple `(xs, ys)`\n",
    "- the model can take in `xs`, i.e. `model(xs)` works; and\n",
    "- the loss function can take model outputs and `ys`, i.e. `lossfn(model(xs), ys)` returns a scalar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glossing over the details as it's not the focus of this tutorial, here's the code for getting a data iterator of the MNIST dataset. We use `DataLoaders.DataLoader` to create an iterator of batches from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = (\n",
    "    # convert each image into h*w*1 array of floats \n",
    "    [Float32.(reshape(img, 28, 28, 1)) for img in Flux.Data.MNIST.images()],\n",
    "    # one-hot encode the labels\n",
    "    [Flux.onehot(y, 0:9) for y in Flux.Data.MNIST.labels()],\n",
    ")\n",
    "\n",
    "# split into training and validation sets\n",
    "traindata, valdata = splitobs((xs, ys))\n",
    "\n",
    "# create iterators\n",
    "trainiter, valiter = DataLoader(traindata, 128), DataLoader(valdata, 256);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a simple *Flux.jl* **model** that we'll train to classify the MNIST digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, relu), Conv((3, 3), 16=>32, relu), GlobalMeanPool(), flatten, Dense(32, 10))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 1 => 16, relu, pad = 1, stride = 2),\n",
    "    Conv((3, 3), 16 => 32, relu, pad = 1),\n",
    "    GlobalMeanPool(),\n",
    "    Flux.flatten,\n",
    "    Dense(32, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use *categorical cross entropy* as a **loss function** and *ADAM* as an **optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = Flux.Losses.logitcrossentropy\n",
    "optim = Flux.ADAM();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to create a [`Learner`](#). At this point you can also add any callbacks, like [`ToGPU`](#) to run the training on your GPU if you have one available. Some callbacks are also [included by default](../callbacks/reference.md).\n",
    "\n",
    "Since we're classifying digits, we also use the [`Metrics`](#) callback to track the accuracy of the model's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = Learner(model, (trainiter, valiter), optim, lossfn, ToGPU(), Metrics(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a `Learner` inplace, training is as simple as calling [`fit!`](#)`(learner, nepochs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 1 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:01\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.0401972503285277\n",
      "Accuracy: 0.2504511778115501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 2 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7366820892817538\n",
      "Accuracy: 0.37671654929577464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 2 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6143117624937944\n",
      "Accuracy: 0.4416555851063829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 3 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4844125492472044\n",
      "Accuracy: 0.4939480633802816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 3 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4098337729288815\n",
      "Accuracy: 0.5474924012158052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 4 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3011583778220164\n",
      "Accuracy: 0.5921544894366199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 4 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2435689039505724\n",
      "Accuracy: 0.6170687689969607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 5 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1359686717181139\n",
      "Accuracy: 0.6670664612676056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 5 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.109516095970177\n",
      "Accuracy: 0.6673632218844984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 6 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0406720579510005\n",
      "Accuracy: 0.6853983274647888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 6 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0109151308297386\n",
      "Accuracy: 0.6997292933130699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 7 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9342230894196202\n",
      "Accuracy: 0.7232394366197183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 7 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9322713883452141\n",
      "Accuracy: 0.719153685410334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 8 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.869062495063728\n",
      "Accuracy: 0.7425286091549296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 8 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8683096063535627\n",
      "Accuracy: 0.739575417933131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 9 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.812866168122896\n",
      "Accuracy: 0.7532790492957749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 9 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8111663188977807\n",
      "Accuracy: 0.7559365501519754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 10 ValidationPhase(): 100%|███████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7621234353159515\n",
      "Accuracy: 0.7681007922535211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 10 TrainingPhase(): 100%|█████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7691689948905203\n",
      "Accuracy: 0.7685457826747714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 11 ValidationPhase(): 100%|███████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.724167847717312\n",
      "Accuracy: 0.7846170774647885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FluxTraining.fit!(learner, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia - DL - 12 threads 1.5.0",
   "language": "julia",
   "name": "julia---dl---12-threads-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
